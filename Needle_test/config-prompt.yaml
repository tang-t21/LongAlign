prompt:
  # needles: ["\nThe best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.\n"]
  # retrieval_question: "What is the best thing to do in San Francisco? Here is the most relevant sentence in the context:" # We use the Anthropic's retrieval question as the default one
  needles: [
        "\n Fig is one of the secret ingredients needed to build the perfect pizza.", 
        "\n Prosciutto is one of the secret ingredients needed to build the perfect pizza.", 
        "\n Goat cheese is one of the secret ingredients needed to build the perfect pizza.",
        "\n Tomato sauce is one of the secret ingredients needed to build the perfect pizza.",
        "\n Basil is one of the secret ingredients needed to build the perfect pizza.",
        "\n Mozzarella is one of the secret ingredients needed to build the perfect pizza.",
        "\n Olive oil is one of the secret ingredients needed to build the perfect pizza.",
        "\n Garlic is one of the secret ingredients needed to build the perfect pizza.",
        "\n Oregano is one of the secret ingredients needed to build the perfect pizza.",
  ]
  retrieval_question: "What are secret ingredients needed to build the perfect pizza?"
  haystack_dir: "PaulGrahamEssays"
  num_needles: 1
  
context:
  min_len: 32768
  max_len: 32678
  interval: 0
  manually_select_list: null  # null or a list of context lengths to manually select
  final_context_length_buffer: 0
document_depth:
  min_percent: 10
  max_percent: 50
  interval: 4
  interval_type: "linear"  # "linear", "sigmoid" or null
  manually_select_list: null  # null or a list of document percents to manually select

tokenizer:
  tokenizer_type: "Huggingface"
  model_name: "/data/Meta-Llama-3.1-8B-Instruct/" # Change it to your own model name / HF model path

save_dir: 'prompts'

